# mini-scm-interpreter

> 说明：语言的开发经常和高大上的编译原理关联让许多人望而却步，现在我们退后一步先放弃从零开始打造编译器的雄心壮志从已有语言来构建属于自己的语言。
> 为什么要了解一套语言？对于不同层的技术问题都需要开发自己的一套语言从而屏蔽细节，对上提供更好的抽象。比如机器语言，高级语言，业务语言等，每一层
> 都在尽力提供自己的一套词汇从而方便问题的划分和归一。总而言之，程序员不在仅仅是会使用咒语的魔法师还应该是语言的设计师。


本解释器`Mini-SCM-Interpreter` 基于书籍《计算机程序的构造和解释》的元语言抽象写出，目的在于更好的理解语言，解开语言背后的面纱。

- V1: Token和语法树解析
- V2: 增加 `Eval-Apply` 结构
- V3: 支持内置函数比如`max`, `min`...
- V4: 支持动态Lambda
- V5: 支持Macro
- V6: 尾递归优化
- V7: 惰性求值
- V8: 支持非确定性计算

## Token和语法树解析

### Token解析

解析Token的过程在于把字符串转变为可以被解释器【这里是Python】解释的符号比如

- `#t` 解析为`True`
- `"3.14"` 解析为 `3.14`
- `age` 解析为名称标识符`age`

Token解析可以归纳为从左往右扫描token符号并应用解析规则识别，详细的规则参考`Tokenizer._TOKEN_TYPE_EXTRACT_RULE`。

**扫描符号**

- 如果是注释符号则跳过
- 遇到空白跳过
- 记录单个分隔符`()'`则记录该token和位置
- 对其他表示符号名称等截取该位置到最近的一个空白符或则分隔符为止比如`max(a,b)`对`max`而言需要解析到`(`的位置

**识别Token值**

将解析规则应用于解析的token符号，核心过程如下

```python
def _gen_token_stream(self, line: str):
    """解析token，丢弃空白文本和注释"""
    token, next_token_idx = _next_candidate_token(line, 0)

    while token:
        if (res := self._extract_token(token)) is not None:
            yield res
        else:
            _raise_token_value_exception(line, token, next_token_idx)
        token, next_token_idx = _next_candidate_token(line, next_token_idx)
```

### 语法树解析

`lisp`的语法天然贴合语法树的表示比如`(define (abs x) (if (< x 0) (- x) x ) )`对应的语法树示意图如下。


```
┌───────┬───┐     ┌─────┬────┐          ┌───┬────┐                                                  
│ define│ . ┼─────┤ .   │ .  ├────────► │ . │ nil│                                                  
└───────┴───┘     └─┬───┴────┘          └─┬─┴────┘                                                  
                    │                     │                                                         
                    ▼                     ▼                                                         
                  ┌─────┬────┐          ┌─────┬────┐       ┌───┬────┐      ┌───┬────┐     ┌───┬────┐
                  │abs  │ .  │          │ if  │ .  ├─────► │.  │ .  │ ────►│.  │  . │ ──► │ x │nil │
                  └─────┴─┬──┘          └─────┴────┘       └─┬─┴────┘      └─┬─┴────┘     └───┴────┘
                          │                                  ▼               │                      
                       ┌──▼─┬─────┐                        ┌────┬───┐      ┌─▼──┬───┐               
                       │  x │ nil │                        │ <  │ . │      │ -  │ . │               
                       └────┴─────┘                        └────┴─┬─┘      └────┴─┬─┘               
                                                                  │               │                 
                                                                  │               │                 
                                                                 ┌▼─┬─────┐      ┌▼─┬─────┐         
                                                                 │x │  .  │      │x │ nil │         
                                                                 └──┴──┬──┘      └──┴─────┘         
                                                                       │                            
                                                                       ▼                            
                                                                      ┌──┬──────┐                   
                                                                      │0 │ nill │                   
                                                                      └──┴──────┘                                                                                                                          
```

解析规则将token流分为二部分，一部分为expr处理解析对象，指针部分由rest解析。

对expr来说处理能够被直接解析的部分
- 遇到`(`则返回rest部分
- 遇到`nil`则返回nil对象
- 遇到符号则返回符号
- 遇到引用则构建一个引用pair然后继续调用expr递归解析

对rest函数而言负责递归构建`Pair(expr(), rest()))`,结束条件为遇到了终止符`)`则认为本次解析结束，具体解析参考`Parser.parser()`

这样一个代表语法树的解析完成，接下来开始支持最核心的功能`Eval-Apply`结构